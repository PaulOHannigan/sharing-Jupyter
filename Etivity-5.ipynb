{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etivity-5 Paul O'Hannigan\n",
    "## Regression and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Repeat the experiment in Lab5 - Regression and Dimensionality Reduction.ipynb with winequality_white.csv and draw conclusions from the results you observe in a markdown cell.\n",
    "### Task 3\n",
    "\n",
    "Add two dimensionality-reduction methods which are not used in Lab5 - Regression and Dimensionality Reduction.ipynb to the training pipelines. Aim at dimensionality reduction techniques which are sufficiently different from the ones used in the example notebook.\n",
    "### Task 4\n",
    "\n",
    "Experiment with a third regression algorithm. Describe how it compares to Random Forest and Linear regression in a markdown cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this exercise we train a regression model, i.e. a model for numeric prediction. We also add dimensionality reduction element to the training pipeline. Note that dimensionality reduction can be included in classification pipelines in the same way. \n",
    "\n",
    "In this exercise we use the `winequality-white` dataset, taken from https://archive.ics.uci.edu/ml/datasets/wine+quality. Each example in this dataset represents a particular white wine. The columns (i.e. the features) are numerical characteristics of the wines. One of them is the `quality` of the wine on a scale from 3 to 8, and all others are chemical characteristics of the wine. \n",
    "\n",
    "We aim which at training a regression model for predicting the quality of a white wine. We will evaluate two regression algorithms, `RandomForestRegressor` and `LinearRegression`, to choose the better one for training the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# imports necessary for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# regression algorithms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# metrics for evaluating regression models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset, make a copy of the dataset, check for missing values and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"./winequality-white.csv\")\n",
    "\n",
    "# Create a copy of the original dataset\n",
    "df_original= df.copy()\n",
    "\n",
    "# Describe the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values and outliers.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values. Let's check the boxplots of all columns except `quality` for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(figsize=(20,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `residual sugar`, `free sulfur dioxide` and `total sulfur dioxide` appear to have most prominent outliers. We will apply log transformation followed by `RobustScaler` to both of them. To all other columns (except `quality`) we will apply `StandardScaler`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to prepare two lists of column names. The list `names_outliers` contains the names of the two columns to which we will apply log transformation followed by `RobustScaler`. The list `names_no_outliers` contains the names of all other columns (except `quality`) to which we will apply `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store a list with the names of all predictors\n",
    "names_all = [c for c in df if c not in ['quality']]\n",
    "\n",
    "# define column groups with the same data preparation\n",
    "names_outliers = ['residual sugar', 'free sulfur dioxide', 'total sulfur dioxide']\n",
    "names_no_outliers = list(set(names_all) - set(names_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting a dataset into a training and test sets, the names of the columns are lost. This is the reason, we stored the names of the columns in lists above. We will use the following class in the preprocessing pipeline to put the names of the columns back. We need this to easily apply the different preparation strategies to the two groups of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddColumnNames(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(data=X, columns=self.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need another class to be able to select a particular group of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can build the preprocessing pipeline. It first adds the column names back to a set of examples (that can be either a training, or a validation, or test set). Then it applies the two different data preparation strategies to the two groups of columns and unites them with `FeatureUnion`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = make_pipeline(\n",
    "    AddColumnNames(columns=names_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_outliers),\n",
    "            FunctionTransformer(np.log, validate=True),\n",
    "            RobustScaler()\n",
    "        )),\n",
    "        (\"no_outlier_columns\", make_pipeline(\n",
    "            ColumnSelector(columns=names_no_outliers),\n",
    "            StandardScaler()\n",
    "        ))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can separate the columns into *target* and *predictors* and split the dataset into a training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['quality']\n",
    "X = df.drop('quality', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we treat `quality` as a numerical attribute, it is in fact ordinal, and we can still do a stratified split to ensure that the distribution of wine qualities is the same in both the training and the test sets.\n",
    "\n",
    "Note that after the split into a training and test sets, X_train and X_test are numpy arrays and no longer have column names. That's why we needed the class above to put the names of columns back in the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Best Parameters and Best Dimensionality Reduction Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train `RandomForestRegressor` on the training set with a range of possible parameters in order to find the best parameters by cross-validation. To do this we will build another [main] pipeline which includes the preprocessing pipeline and `RandomForestRegressor`. We also add an element for dimensionality reduction after the preprocessing pipeline.\n",
    "\n",
    "Here we will attempt five different dimensionality reduction methods and we will let the grid search pick the best one. These are:\n",
    "\n",
    ">Task2:\n",
    "- Principal Component Analysis (PCA)\n",
    "- Recursive Feature Elimination (RFE) with estimators `svm.SVR` and `LinearRegression`<br>\n",
    "\n",
    ">Task3:\n",
    "- TrucatedSVD: `radomized` and `arpack`\n",
    "- Factory Analysis: `radomized` and `arpack`\n",
    "\n",
    "Note that RFE is using regression algorithms for selecting the best features; these regression algorithms can be different from the regression algorithm at the end of the main pipeline.\n",
    "\n",
    "The main pipeline will take care for separately preprocessing the training and validation sets after the training set is further split into training and validation sets in the process of cross-validation. It also applies the dimensionality reduction method separately to the two sets.\n",
    "\n",
    "Links to the Scikit references for TrucatedSVD and Factory Analysis can be found here:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FactorAnalysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline contains a placeholder for the dimensionality reduction method. We will treat the method as a parameter and let the grid search pick the best of the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', RandomForestRegressor(n_estimators=10))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit the parameter grid to a few options for the `max_depth` parameter of `RandomForestRegressor` and to three alternative values for the number of selected features by the dimensionality reduction method. More parameters and values can be explored. Here we limit the options to make sure the grid search does not take too long to execute.  After some trial and error I limited the parameter values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.450:\n",
      "Best parameters:  {'reduce_dim': FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=10,\n",
      "               noise_variance_init=None, random_state=0, svd_method='lapack',\n",
      "               tol=0.01), 'reduce_dim__n_components': 10}\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [10, 12]\n",
    "MAX_FEATURES_OPTIONS = [8, 10]\n",
    "MAX_DEPTH_OPTIONS = [8, 10, 12]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': MAX_FEATURES_OPTIONS,\n",
    "        'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')), RFE(LinearRegression())],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "        'reduce_dim__n_components': MAX_FEATURES_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [FactorAnalysis(svd_method='randomized'), FactorAnalysis(svd_method='lapack')],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=10, iid = False, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "RF_best_params = search.best_params_\n",
    "RF_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explicitly assign the `False` to the parameter `iid` of `GridSearchCV` to avoid a deprecation warning. The parameter `refit=True` makes the `GridSearchCV` train a `RandomForestRegressor` model on the **whole training set** with the best parameters and the best dimensionality reduction method found. This best model can then be accessed via the `.best_estimator_` attribute of the `GridSearchCV`.  \n",
    "\n",
    "I found that I had to create two `n_components` arrays as the values for `PCA` and `TruncatedSCV` must be between 0 and 11 wheres the other methods can take higher values.\n",
    "\n",
    "With the given set of values, the `factory analysis` method with the svd_method `lapack` achieves the best CV score of 0.45\n",
    "\n",
    "We repeat the same experiment but with `LinearRegression` for training a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we limit the parameter grid to one parameter of `LinearRegression` and two alternative values for the number of selected features to make sure the grid search does not take too long to execute.   After some trial and error I limited the parameter values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.292:\n",
      "Best parameters:  {'reduce_dim': RFE(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "                  gamma='auto', kernel='linear', max_iter=-1, shrinking=True,\n",
      "                  tol=0.001, verbose=False),\n",
      "    n_features_to_select=8, step=1, verbose=0), 'reduce_dim__n_features_to_select': 8, 'regresson__normalize': False}\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [8, 10]\n",
    "NORMALIZE_OPTIONS = [False, True]\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "       'reduce_dim': [PCA(iterated_power=7)],\n",
    "       'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "       'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')),RFE(LinearRegression())],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [FactorAnalysis(svd_method='randomized'), FactorAnalysis(svd_method='lapack')],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=10, iid=False, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "LR_best_params = search.best_params_\n",
    "LR_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the given set of values, the `RFE` method with the estimator `svm.SVR` achieves the best CV score of 0.292.\n",
    "\n",
    "Let's repeat the same experiment but with `GradientBoostingRegressor` for training a regression model.  After some trial and error I limited the parameter values accordingly.  A link to the Scikit references for TrucatedSVD and Factory Analysis can be found here:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html?highlight=gradientboostingregressor#sklearn.ensemble.GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression Pipeline (Task 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', GradientBoostingRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.500:\n",
      "Best parameters:  {'reduce_dim': RFE(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "                  gamma='auto', kernel='linear', max_iter=-1, shrinking=True,\n",
      "                  tol=0.001, verbose=False),\n",
      "    n_features_to_select=12, step=1, verbose=0), 'reduce_dim__n_features_to_select': 12, 'regresson__max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [10, 12]\n",
    "MAX_FEATURES_OPTIONS = [8, 10]\n",
    "MAX_DEPTH_OPTIONS = [6, 8]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': MAX_FEATURES_OPTIONS,\n",
    "        'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')), RFE(LinearRegression())],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [TruncatedSVD(algorithm='randomized'), TruncatedSVD(algorithm='arpack')],\n",
    "        'reduce_dim__n_components': MAX_FEATURES_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [FactorAnalysis(svd_method='randomized'), FactorAnalysis(svd_method='lapack')],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS\n",
    "    }\n",
    "]\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=10, iid=False, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "GB_best_params = search.best_params_\n",
    "GB_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the given set of values, the RFE method with the estimator svm.SVR achieves the best CV score of 0.500.\n",
    "\n",
    "The results suggest that `GradientBoostingRegressor` performs better. The cross-validation score is `1 - relative squared error`. The higher the score the more accurate the model. We can now further confirm this by comparing the best models on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Regression Models on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the best models found by the grid search on the test dataset and compare their metrics:\n",
    "\n",
    "- mean squared error (MSE)\n",
    "- mean absolute error (MAE)\n",
    "- 1-relative squared error (R2)\n",
    "\n",
    "to choose the better regressor for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model - a trained regression model\n",
    "\n",
    "def evaluate_model(X_test, y_test, model):\n",
    "    \n",
    "    # compute prediction for the test set\n",
    "    _predicted_values = model.predict(X_test)\n",
    "        \n",
    "    # compute metrics\n",
    "    _mse = mean_squared_error(y_test, _predicted_values)\n",
    "    _mae = mean_absolute_error(y_test, _predicted_values)\n",
    "    _r2 = r2_score(y_test, _predicted_values)\n",
    "            \n",
    "    return _mse, _mae, _r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the function above to evaluate the best Random Forest, Linear Regression and Gradient Boosting Regressor models found by the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_mse, RF_mae, RF_r2 = evaluate_model(X_test, y_test, RF_best_model)\n",
    "LR_mse, LR_mae, LR_r2 = evaluate_model(X_test, y_test, LR_best_model)\n",
    "GB_mse, GB_mae, GB_r2 = evaluate_model(X_test, y_test, GB_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Pandas bar plot to compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RF_metrics = np.array([RF_mse, RF_mae, RF_r2])\n",
    "LR_metrics = np.array([LR_mse, LR_mae, LR_r2])\n",
    "GB_metrics = np.array([GB_mse, GB_mae, GB_r2])\n",
    "index = ['MSE', 'MAE', 'R2']\n",
    "df_metrics = pd.DataFrame({'Random Forest': RF_metrics, 'Linear Regression': LR_metrics, 'Gradient Boosting Regressor': GB_metrics}, index=index)\n",
    "df_metrics.plot.bar(rot=0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tests confirms that for the given dataset, optimised parameter values and the selected dimensionality reduction methods that `GradientBoostingRegressor` is the better regression model with lower MSE and MAE and higher R2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train a  `GradientBoostingRegressor` model with all the data we have, assuming that the more data we have the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the string 'regresson__' from the names of the best parameters\n",
    "def transform(dict, prefix):\n",
    "    dict_prefix = {key:value for key,value in dict.items() if prefix in key}\n",
    "    return {key.replace(prefix,''):value for key,value in dict_prefix.items()}\n",
    "\n",
    "pipe = make_pipeline(preprocess_pipeline, \n",
    "                     GB_best_params.get('reduce_dim'),\n",
    "                     GradientBoostingRegressor(**transform(GB_best_params, 'regresson__')))\n",
    "\n",
    "final_model =pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store this model on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
